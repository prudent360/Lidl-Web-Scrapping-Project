{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1d498e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import mechanize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c9778",
   "metadata": {},
   "source": [
    "### Creating a Browser Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "335ecf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "br = mechanize.Browser()\n",
    "br.set_handle_robots(False)  # Google demands a user-agent that isn't a robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "58d2dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "br.addheaders = [(\"User-agent\", \"Edge\")]  # if chrome is not installed, you may also select 'firefox'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686eb8d",
   "metadata": {},
   "source": [
    "### Opening a web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d4fd4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Lidl web page\n",
    "response = br.open(\"https://uk.trustpilot.com/review/www.lidl.co.uk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fdf8f8",
   "metadata": {},
   "source": [
    "## Exercise 2: Scraping the Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa7fa372",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page = response.read()\n",
    "soup = BeautifulSoup(web_page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b55c8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets all the reviews from the store\n",
    "#soup.select('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "842ca0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the first review from the store\n",
    "#soup.select('article')[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986604ba",
   "metadata": {},
   "source": [
    "### Getting Authors of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4cf6f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J Q\n",
      "Elizabeth Beirne\n",
      "Mohammed\n",
      "Magda Fellino\n",
      "Stephen\n",
      "Adam Cadman\n",
      "Christine Espley\n",
      "Mohammed\n",
      "J Q\n",
      "Elizabeth Beirne\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each <article> tag (each review) \n",
    "for article in soup.select('article')[:10]:\n",
    "    # finding the tags associated to the article\n",
    "    author_element = article.find('span', class_=\"typography_heading-xs__osRhC typography_appearance-default__t8iAq\", \n",
    "                                  attrs={\"data-consumer-name-typography\": \"true\"})\n",
    "    if author_element:\n",
    "        review_author = author_element.text.strip()\n",
    "        print(review_author)\n",
    "    else:\n",
    "        print(\"No Title Found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5418a204",
   "metadata": {},
   "source": [
    "### Getting the title of review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ff31ca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Title Found!\n",
      "No Title Found!\n",
      "No Title Found!\n",
      "No Title Found!\n",
      "Con artists\n",
      "Lidl - my most useful supermarket!\n",
      "Nordic “promotion” my aunt sally.\n",
      "Arrogant aggressive accusing blaming dishonest managers\n",
      "Lawrence Hill store\n",
      "huge clump of hair in cretan pies…nice\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each <article> tag (each review) \n",
    "for article in soup.select('article')[:10]:\n",
    "    # finding the tags associated to the review title\n",
    "    title_element = article.find('h2', class_=\"typography_heading-xs__osRhC typography_appearance-default__t8iAq\", \n",
    "                                  attrs={\"data-service-review-title-typography\": \"true\"})\n",
    "    if title_element:\n",
    "        title = title_element.text.strip()\n",
    "        print(title)\n",
    "    else:\n",
    "        print(\"No Title Found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92076290",
   "metadata": {},
   "source": [
    "### Combining the code to get both author and review title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2e36e9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: J Q\n",
      "Title: None\n",
      "--------------------\n",
      "Author: Elizabeth Beirne\n",
      "Title: None\n",
      "--------------------\n",
      "Author: Mohammed\n",
      "Title: None\n",
      "--------------------\n",
      "Author: Magda Fellino\n",
      "Title: None\n",
      "--------------------\n",
      "Author: Stephen\n",
      "Title: Con artists\n",
      "--------------------\n",
      "Author: Adam Cadman\n",
      "Title: Lidl - my most useful supermarket!\n",
      "--------------------\n",
      "Author: Christine Espley\n",
      "Title: Nordic “promotion” my aunt sally.\n",
      "--------------------\n",
      "Author: Mohammed\n",
      "Title: Arrogant aggressive accusing blaming dishonest managers\n",
      "--------------------\n",
      "Author: J Q\n",
      "Title: Lawrence Hill store\n",
      "--------------------\n",
      "Author: Elizabeth Beirne\n",
      "Title: huge clump of hair in cretan pies…nice\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for article in soup.select('article')[:10]:\n",
    "    try:\n",
    "        # Correctly extract author using proper class name\n",
    "        author_tag = article.find('span', class_=\"typography_heading-xs__osRhC typography_appearance-default__t8iAq\")\n",
    "        author = author_tag.text.strip() if author_tag else None  # Fixed ternary operator syntax\n",
    "        \n",
    "        # Extract title from h2 tag with proper handling\n",
    "        title_tag = article.find('h2')\n",
    "        title = title_tag.text.strip() if title_tag else None  # Added .strip() for cleanliness\n",
    "\n",
    "    except Exception as inner_e:\n",
    "        print(f\"Error processing a review: {inner_e}\")\n",
    "        continue  # Skip to next iteration if error occurs\n",
    "\n",
    "    # Print statements moved outside the try-except block\n",
    "    print(f\"Author: {author}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(\"-\" * 20)  # Separator between reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212179a3",
   "metadata": {},
   "source": [
    "### Extracting the review date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c32da4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_article = soup.select('article')[5]\n",
    "p_tag = ex_article.find('p', class_=\"typography_body-m__k2UI7 typography_appearance-default__t8iAq\",\n",
    "                        attrs={\"data-service-review-date-of-experience-typography\": \"true\"})\n",
    "span_tag = p_tag.find('span', class_=\"typography_body-m__k2UI7 typography_appearance-subtle__PYOVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f58e004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: J Q\n",
      "Title: None\n",
      "Date: N/A\n",
      "--------------------\n",
      "Author: Elizabeth Beirne\n",
      "Title: None\n",
      "Date: N/A\n",
      "--------------------\n",
      "Author: Mohammed\n",
      "Title: None\n",
      "Date: N/A\n",
      "--------------------\n",
      "Author: Magda Fellino\n",
      "Title: None\n",
      "Date: N/A\n",
      "--------------------\n",
      "Author: Stephen\n",
      "Title: Con artists\n",
      "Date: 21 March 2025\n",
      "--------------------\n",
      "Author: Adam Cadman\n",
      "Title: Lidl - my most useful supermarket!\n",
      "Date: 21 March 2025\n",
      "--------------------\n",
      "Author: Christine Espley\n",
      "Title: Nordic “promotion” my aunt sally.\n",
      "Date: 15 March 2025\n",
      "--------------------\n",
      "Author: Mohammed\n",
      "Title: Arrogant aggressive accusing blaming dishonest managers\n",
      "Date: 04 February 2025\n",
      "--------------------\n",
      "Author: J Q\n",
      "Title: Lawrence Hill store\n",
      "Date: 20 March 2025\n",
      "--------------------\n",
      "Author: Elizabeth Beirne\n",
      "Title: huge clump of hair in cretan pies…nice\n",
      "Date: 19 March 2025\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for article in soup.select('article')[:10]:\n",
    "    try:\n",
    "        # Correct class name formatting with proper string continuation\n",
    "        author_tag = article.find('span', \n",
    "            class_=\"typography_heading-xs__osRhC typography_appearance-default__t8iAq\")\n",
    "        author = author_tag.text.strip() if author_tag else None\n",
    "        \n",
    "        title_tag = article.find('h2')\n",
    "        title = title_tag.text.strip() if title_tag else None\n",
    "        \n",
    "        # Fix attribute selector syntax and add error handling\n",
    "        date_element = article.select_one('[data-service-review-date-of-experience-typography]')\n",
    "        date_text = date_element.text if date_element else \"N/A\"\n",
    "        dates = date_text.split(':')[-1].strip() if ':' in date_text else date_text\n",
    "\n",
    "    except Exception as inner_e:\n",
    "        print(f\"Error processing a review: {inner_e}\")\n",
    "        continue  # Skip to next review if error occurs\n",
    "\n",
    "    # Print statements moved outside the try block\n",
    "    print(f\"Author: {author}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Date: {dates}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edcb4c5",
   "metadata": {},
   "source": [
    "### Extracting review rating and review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "891a350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: J Q\n",
      "Title: None\n",
      "Date: N/A\n",
      "Rating: N/A\n",
      "Review Text: None\n",
      "----------------------------------------\n",
      "Author: Elizabeth Beirne\n",
      "Title: None\n",
      "Date: N/A\n",
      "Rating: N/A\n",
      "Review Text: None\n",
      "----------------------------------------\n",
      "Author: Mohammed\n",
      "Title: None\n",
      "Date: N/A\n",
      "Rating: N/A\n",
      "Review Text: None\n",
      "----------------------------------------\n",
      "Author: Magda Fellino\n",
      "Title: None\n",
      "Date: N/A\n",
      "Rating: N/A\n",
      "Review Text: None\n",
      "----------------------------------------\n",
      "Author: Stephen\n",
      "Title: Con artists\n",
      "Date: 21 March 2025\n",
      "Rating: Rated 1 out of 5 stars\n",
      "Review Text: Con artists, offer you a free item etc, but if you buy more than one eligible they take the cheapest item off...joke\n",
      "----------------------------------------\n",
      "Author: Adam Cadman\n",
      "Title: Lidl - my most useful supermarket!\n",
      "Date: 21 March 2025\n",
      "Rating: Rated 5 out of 5 stars\n",
      "Review Text: I use my local Lidl (Binley Road, Coventry) for most of my shopping as it's within walking distance.The staff are friendly, and many recognise me and say Hi.The store, right at the end of the day can be a bit grubby but which supermarkets aren't? The rest of the time it's clean and (mostly!) well stocked.Anything they can improve?The offers on the app are too short lived - 7 days to accept an offer then 7 days to use it. By contrast, I recently went to Tesco (first time in months) and there were tokens waiting to be cashed on their card I appreciate that indefinite tokens aren't feasible, but 7 days is too short. Even just 14 days would be a huge improvement!\n",
      "----------------------------------------\n",
      "Author: Christine Espley\n",
      "Title: Nordic “promotion” my aunt sally.\n",
      "Date: 15 March 2025\n",
      "Rating: Rated 1 out of 5 stars\n",
      "Review Text: Went to Lidl in Cirencester, Woodley and Reading for the Nordic promotion. No meatballs, no Falukorv sausage. What a joke this company is. Will I get a reply, “Sorry to hear this!”  Useless shop.\n",
      "----------------------------------------\n",
      "Author: Mohammed\n",
      "Title: Arrogant aggressive accusing blaming dishonest managers\n",
      "Date: 04 February 2025\n",
      "Rating: Rated 1 out of 5 stars\n",
      "Review Text: Falsely accused of shopping. Aggressively stopped by security. Aggressive blaming accusing extremely arrogant managers with no customer service skill. Experts in confrontation. After checking my bags woefully non existent apology in an aggressive manner. Falsely teamed up and accused me an old man of coming up to. Never seen more arrogant managers in my life.\n",
      "----------------------------------------\n",
      "Author: J Q\n",
      "Title: Lawrence Hill store\n",
      "Date: 20 March 2025\n",
      "Rating: Rated 1 out of 5 stars\n",
      "Review Text: Lawrence Hill store - long wait at both manned and self service checkouts, due to withdrawal of small baskets and customers using self service checkouts for large amounts of shopping.   Also, staff had great difficulty sorting out the price of an item at the checkout (seemed to be a fault on the computer system).   Poor approach from store manager - very defensive and no apologies to customers for the excessive delay and inconvenience.\n",
      "----------------------------------------\n",
      "Author: Elizabeth Beirne\n",
      "Title: huge clump of hair in cretan pies…nice\n",
      "Date: 19 March 2025\n",
      "Rating: Rated 1 out of 5 stars\n",
      "Review Text: huge clump of hair in cretan pies frozen from the greek range, tried to call but can only do on whatsapp, they will not take a call and when i messaged someone, they said they could not call me back.  Customer service is non existent, not interested...they do not want to listen to their customers then....appalling, would give zero stars if i could\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for article in soup.select('article')[:10]:\n",
    "    try:\n",
    "        author_tag = article.find('span', \n",
    "                                  class_=\"typography_heading-xs__osRhC typography_appearance-default__t8iAq\")\n",
    "        author = author_tag.text.strip() if author_tag else None  # Fixed variable name check\n",
    "        \n",
    "        title_tag = article.find('h2')  # Replace 'h2' with the correct tag (e.g., 'h3', 'div')\n",
    "        title = title_tag.text.strip() if title_tag else None\n",
    "        \n",
    "        # Date\n",
    "        date_element = article.select_one('[data-service-review-date-of-experience-typography]')\n",
    "        dates = date_element.text.split(':')[-1].strip() if date_element else \"N/A\"\n",
    "        \n",
    "        # Rating\n",
    "        rating_element = article.select_one('[data-service-review-rating] img')\n",
    "        rating = rating_element['alt'] if rating_element else \"N/A\"  # Removed trailing comma\n",
    "        \n",
    "        # Review text\n",
    "        review_text_element = article.select_one('[data-service-review-text-typography]')\n",
    "        review_text = review_text_element.text.strip() if review_text_element else None\n",
    "        \n",
    "\n",
    "    except Exception as inner_e:\n",
    "        print(f\"Error processing a review: {inner_e}\")\n",
    "        continue  # Skip to next review if error occurs\n",
    "\n",
    "    # Print statements moved outside the try block for clarity\n",
    "    print(f\"Author: {author}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Date: {dates}\")\n",
    "    print(f\"Rating: {rating}\")\n",
    "    print(f\"Review Text: {review_text}\")\n",
    "    print(\"-\" * 40)  # Separator between reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade70f7",
   "metadata": {},
   "source": [
    "## Saving All Reviews to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ec4c94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "70ca9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all reviews\n",
    "all_reviews = []\n",
    "\n",
    "# Loop through pages (adjust 'max_pages' as needed)\n",
    "max_pages = 5  # Change this to scrape more pages\n",
    "for page_num in range(1, max_pages + 1):\n",
    "    try:\n",
    "        # Construct URL with page number\n",
    "        url = f\"https://uk.trustpilot.com/review/www.lidl.co.uk?page={page_num}\"\n",
    "        \n",
    "        # Extract reviews from current page\n",
    "        articles = soup.select('article')\n",
    "        \n",
    "        for article in articles:\n",
    "            try:\n",
    "                # Extract author\n",
    "                \n",
    "                author_tag = article.find('span',\n",
    "                                  class_=\"typography_heading-xs__osRhC typography_appearance-default__t8iAq\")\n",
    "                author = author_tag.text.strip() if author_tag else None\n",
    "            \n",
    "                \n",
    "                # Extract title\n",
    "                title_tag = article.find('h2')\n",
    "                title = title_tag.text.strip() if title_tag else None  # Added .strip() for cleanliness\n",
    "                \n",
    "                # Extract date\n",
    "                date_element = article.select_one('[data-service-review-date-of-experience-typography]')\n",
    "                date_text = date_element.text if date_element else \"N/A\"\n",
    "                review_date = date_text.split(':')[-1].strip() if ':' in date_text else date_text\n",
    "                \n",
    "                \n",
    "                # Extract rating\n",
    "                rating_element = article.select_one('[data-service-review-rating] img')\n",
    "                rating = rating_element['alt'] if rating_element else \"N/A\"\n",
    "                \n",
    "                # Extract review text\n",
    "                review_text_element = article.select_one('[data-service-review-text-typography]')\n",
    "                review_text = review_text_element.text.strip() if review_text_element else None\n",
    "                \n",
    "                # Create dictionary and append to list\n",
    "                review_dict = {\n",
    "                    'review_author': author,\n",
    "                    'review_date_original': review_date,\n",
    "                    'review_title': title,\n",
    "                    'review_rating': rating,\n",
    "                    'review_text': review_text,\n",
    "                    'page_number': page_num\n",
    "                }\n",
    "                all_reviews.append(review_dict)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing a review on page {page_num}: {e}\")\n",
    "                continue  # Skip to next review\n",
    "            \n",
    "        # Add delay to avoid IP blocking\n",
    "#         time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page_num}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "df = pd.DataFrame(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b984a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the 'review_rating' column\n",
    "df['rating'] = df['review_rating'].apply(\n",
    "    lambda x: x.split()[1] if x != 'N/A' else x\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6d90dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering the columns\n",
    "new_column_order = [\n",
    "    'review_author',    # Author name\n",
    "    'review_title',     # Review title\n",
    "    'review_date_original',  # Date of review\n",
    "    'rating',    # Numerical rating (e.g., \"5\")\n",
    "    'review_text',      # Full review text\n",
    "    'page_number'       # Page number scraped from\n",
    "]\n",
    "\n",
    "df = df.reindex(columns=new_column_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d86768c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_author</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_date_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J Q</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elizabeth Beirne</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohammed</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magda Fellino</td>\n",
       "      <td>None</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stephen</td>\n",
       "      <td>Con artists</td>\n",
       "      <td>21 March 2025</td>\n",
       "      <td>1</td>\n",
       "      <td>Con artists, offer you a free item etc, but if...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Paul</td>\n",
       "      <td>Lidl Twickenham please sell to Aldi.</td>\n",
       "      <td>15 March 2025</td>\n",
       "      <td>1</td>\n",
       "      <td>Lidl Twickenham removed numerous tills to inst...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Sweetpea</td>\n",
       "      <td>Taunton Lidls lettuce not chilled- now floppy...</td>\n",
       "      <td>15 March 2025</td>\n",
       "      <td>1</td>\n",
       "      <td>Taunton Lidls now, for some weeks, keeps lettu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Mark Hennessy</td>\n",
       "      <td>Lidl in Fakenham in Norfolk has great…</td>\n",
       "      <td>24 February 2025</td>\n",
       "      <td>5</td>\n",
       "      <td>Lidl in Fakenham in Norfolk has great staff wh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>MR D STALKER</td>\n",
       "      <td>Frustrating</td>\n",
       "      <td>16 March 2025</td>\n",
       "      <td>3</td>\n",
       "      <td>I do like Lidl but find it very frustrating wh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>LOLly</td>\n",
       "      <td>Lidl SHOULD BE ASHAMED</td>\n",
       "      <td>15 March 2025</td>\n",
       "      <td>1</td>\n",
       "      <td>Parking at the Farnham store is too confusing ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_author                                      review_title  \\\n",
       "0                 J Q                                              None   \n",
       "1    Elizabeth Beirne                                              None   \n",
       "2            Mohammed                                              None   \n",
       "3       Magda Fellino                                              None   \n",
       "4             Stephen                                       Con artists   \n",
       "..                ...                                               ...   \n",
       "115              Paul              Lidl Twickenham please sell to Aldi.   \n",
       "116          Sweetpea  Taunton Lidls lettuce not chilled- now floppy...   \n",
       "117     Mark Hennessy            Lidl in Fakenham in Norfolk has great…   \n",
       "118      MR D STALKER                                       Frustrating   \n",
       "119             LOLly                            Lidl SHOULD BE ASHAMED   \n",
       "\n",
       "    review_date_original rating  \\\n",
       "0                    N/A    N/A   \n",
       "1                    N/A    N/A   \n",
       "2                    N/A    N/A   \n",
       "3                    N/A    N/A   \n",
       "4          21 March 2025      1   \n",
       "..                   ...    ...   \n",
       "115        15 March 2025      1   \n",
       "116        15 March 2025      1   \n",
       "117     24 February 2025      5   \n",
       "118        16 March 2025      3   \n",
       "119        15 March 2025      1   \n",
       "\n",
       "                                           review_text  page_number  \n",
       "0                                                 None            1  \n",
       "1                                                 None            1  \n",
       "2                                                 None            1  \n",
       "3                                                 None            1  \n",
       "4    Con artists, offer you a free item etc, but if...            1  \n",
       "..                                                 ...          ...  \n",
       "115  Lidl Twickenham removed numerous tills to inst...            5  \n",
       "116  Taunton Lidls now, for some weeks, keeps lettu...            5  \n",
       "117  Lidl in Fakenham in Norfolk has great staff wh...            5  \n",
       "118  I do like Lidl but find it very frustrating wh...            5  \n",
       "119  Parking at the Farnham store is too confusing ...            5  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6689774b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
